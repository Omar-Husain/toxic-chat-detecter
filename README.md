# ğŸ›¡ï¸ Toxic Chat Detector

By Omar Husain 100491847

**CSCI 4050U - Machine Learning Final Project**

## ğŸ“‹ What It Does

This project uses machine learning to classify chat messages as **toxic** or **not toxic**. It can detect insults, harassment, and hate speech commonly found in online gaming.

**Example:**
- "great game everyone!" â†’ âœ… Not Toxic
- "you are trash at this game" â†’ âš ï¸ Toxic

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd toxic-chat-detector
pip install -r requirements.txt
```

### 2. Train the Model

```bash
python src/train_baseline.py --csv data/gaming_toxic.csv
```

### 3. Run the Web App

```bash
streamlit run app/app_streamlit.py
```

Then open http://localhost:8501 in your browser.

## ğŸ“ Project Structure

```
toxic-chat-detector/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app_streamlit.py    # Web app interface
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ gaming_toxic.csv    # Gaming-specific dataset (~2,200 samples)
â”‚   â”œâ”€â”€ twitter_hate.csv    # Twitter hate speech (~25,000 samples)
â”‚   â””â”€â”€ README.md           # Dataset documentation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_baseline.py   # Train TF-IDF + Logistic Regression model
â”‚   â”œâ”€â”€ train_torch.py      # Train PyTorch neural network (optional)
â”‚   â”œâ”€â”€ infer.py            # Make predictions from command line
â”‚   â”œâ”€â”€ utils.py            # Helper functions
â”‚   â””â”€â”€ metrics.py          # Evaluation metrics
â”œâ”€â”€ artifacts/              # Saved models (created after training)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ exploration.ipynb   # Data exploration notebook
â””â”€â”€ requirements.txt
```

## ğŸ§  How It Works

### Model: TF-IDF + Logistic Regression

1. **TF-IDF**: Converts text into numbers by counting word frequencies
2. **Logistic Regression**: Classifies the numbers as toxic (1) or not toxic (0)

```
"you are trash" â†’ [0.2, 0.1, 0.8, ...] â†’ Model â†’ 0.95 â†’ TOXIC
```

## ğŸ“Š Results

Trained on gaming data (~2,200 samples):

| Metric    | Score |
|-----------|-------|
| Accuracy  | ~94%  |
| Precision | ~95%  |
| Recall    | ~94%  |
| F1 Score  | ~94%  |

## ğŸ’» Commands

```bash
# Train the model
python src/train_baseline.py --csv data/gaming_toxic.csv

# Make a single prediction
python src/infer.py --text "you are awesome"

# Predict from a file
python src/infer.py --file input.csv --output predictions.csv

# Run the web app
streamlit run app/app_streamlit.py

# Train PyTorch model (optional)
python src/train_torch.py --csv data/gaming_toxic.csv
```

## ğŸ“š Datasets

| Dataset | Samples | Best For |
|---------|---------|----------|
| `gaming_toxic.csv` | ~2,200 | Gaming chat detection |
| `twitter_hate.csv` | ~25,000 | General hate speech |

See `data/README.md` for more details.

## ğŸŒ Web App Features

- Enter any message and get instant classification
- Shows confidence score and toxicity bar
- Simple, clean interface

## ğŸ”® Future Improvements

- Use BERT for better accuracy
- Detect specific types of toxicity (insults, threats, etc.)
- Add multi-language support
- Build an API for game integration

## ğŸ‘¤ Author
Omar Husain 100491847
CSCI 4050U - Machine Learning  
Ontario Tech University

## ğŸ“„ License

MIT License

